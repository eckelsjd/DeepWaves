{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import dice\n",
    "from fastai.vision.interpret import SegmentationInterpretation\n",
    "from torch import cuda as cd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from functools import partial\n",
    "\n",
    "# TODO: cleanup accuracy/metrics\n",
    "def acc_camvid(inputs, target):\n",
    "    # DONE: write a generic accuracy function (not camvid)\n",
    "    # type = torch.Tensor\n",
    "    # shape = [B, C, H, W]\n",
    "    # B=num_batches,C=num_classes,H=height,W=width\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    return (inputs.argmax(dim=1)[mask]==target[mask]).float().mean()\n",
    "\n",
    "# Return Jaccard index, or Intersection over Union (IoU) value\n",
    "def jaccard_loss(input:Tensor, targs:Tensor, eps:float=1e-8)->Rank0Tensor:\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        targs: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        input: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model. (prediction)\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = input.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[targs.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(input)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[targs.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(input, dim=1)\n",
    "    true_1_hot = true_1_hot.type(input.type())\n",
    "    dims = (0,) + tuple(range(2, targs.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return jacc_loss\n",
    "\n",
    "# clear GPU cache\n",
    "cd.empty_cache()\n",
    "\n",
    "# get training data\n",
    "path = untar_data(URLs.CAMVID)\n",
    "codes = np.loadtxt(path/'codes.txt',dtype=str)\n",
    "# write codes.txt by hand for desired classes\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['Void']\n",
    "# use 'Void' class for background\n",
    "\n",
    "path_lbl = path/'labels'\n",
    "path_img = path/'images'\n",
    "\n",
    "fnames = get_image_files(path_img)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "\n",
    "# show example image\n",
    "img_f = fnames[10]\n",
    "img = open_image(img_f)\n",
    "img.show(figsize=(5,5))\n",
    "\n",
    "# function to get label path from image filename\n",
    "get_y_fn = lambda x: path_lbl/f'{x.stem}_P{x.suffix}'\n",
    "\n",
    "# show image mask\n",
    "mask = open_mask(get_y_fn(img_f))\n",
    "mask.show(figsize=(5,5), alpha=1)\n",
    "\n",
    "# Training parameters\n",
    "src_size = np.array(mask.shape[1:])\n",
    "# torch.Size([1,720,960]) [C,H,W]\n",
    "# size = src_size // 2 # SMALL round\n",
    "size = src_size        # BIG round\n",
    "bs = 4 # SMALL=12 : BIG=4\n",
    "\n",
    "# Setup Data\n",
    "src = SegmentationItemList.from_folder(path_img)     # GET images\n",
    "# fastai.vision.data.SegmentationItemList :: ItemList\n",
    "\n",
    "src = src.split_by_fname_file(str(path/'valid.txt')) # SPLIT valid/train\n",
    "# fastai.data_block.ItemLists\n",
    "\n",
    "src = src.label_from_func(get_y_fn, classes=codes)    # LABEL classes\n",
    "# fastai.data_block.LabelLists\n",
    "\n",
    "# TODO: replace split_by_fname_file with split_by_rand_pct\n",
    "# TODO: augment dataset with apply_tfms\n",
    "\n",
    "data = (src.transform(get_transforms(),size=size,tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "# fastai.basic_data.DataBunch\n",
    "\n",
    "data.show_batch(rows=3, figsize=(12,9))\n",
    "\n",
    "# Create U-net Learner object\n",
    "learn = unet_learner(data,models.resnet34,metrics=[jaccard_loss,acc_camvid,dice])\n",
    "learn.path = Path(\".\")\n",
    "\n",
    "# TODO: Custom U-net class to implement Refine-Net\n",
    "# TODO: Optimize weight decay and percent start params (wd=0.01 and pct_start=0.3)\n",
    "\n",
    "learn.load('stage-2-big')\n",
    "\n",
    "# TODO: Visualize unet model architecture\n",
    "\n",
    "# Train model (iterative uncomment)\n",
    "\n",
    "# learn.load('stage-1-small')\n",
    "# learn.load('stage-1-big')\n",
    "\n",
    "# STAGE 1 : OPTIMZE learning rate\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot() \n",
    "#     or fig = learn.recorder.plot(return_fig=True); fig.savefig('file.png')\n",
    "# lr = 3e-03\n",
    "# learn.fit_one_cycle(10,slice(lr))\n",
    "# learn.save('stage-1-small')\n",
    "# learn.save('stage-1-big')\n",
    "\n",
    "# STAGE 2 : UNFREEZE\n",
    "# learn.unfreeze()\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()\n",
    "# lower_lr_bound = 4e-05\n",
    "# learn.fit_one_cycle(12,slice(lower_lr_bound,lr/5))\n",
    "# learn.save('stage-2-small')\n",
    "# learn.save('stage-2-big') # FINAL \n",
    "\n",
    "# Results\n",
    "learn.show_results(rows=3,figsize=(8,9))\n",
    "# learn.recorder.plot_losses() # return_fig=True\n",
    "# learn.recorder.plot_lr()     # return_fig=True\n",
    "\n",
    "# Export model\n",
    "# learn.export() # to 'learn.path/'export.pkl'\n",
    "\n",
    "# Inference\n",
    "# learn = load_learner(Path(\".\"))\n",
    "img = open_image(\"920x760.jpg\")\n",
    "res = learn.predict(img) \n",
    "# res = tuple(ImageSegment,Tensor[1,720,960],Tensor[32,720,960])\n",
    "#     = tuple(mask image, class pixel values, probabilities)\n",
    "img.show()\n",
    "res[0].show()\n",
    "img.show(y=res[0]) # y=mask\n",
    "\n",
    "# Stuff that requires Learner to have data loaded\n",
    "interp = SegmentationInterpretation.from_learner(learn)\n",
    "classes = [x for x in learn.data.classes]\n",
    "interp._interp_show(res[0],classes)\n",
    "\n",
    "# TODO: cleanup color/class output\n",
    "# TODO: generate this output on export.pkl alone\n",
    "# TODO: inference on TestBatch\n",
    "\n",
    "# TODO: gather dataset\n",
    "# TODO: label semantic segmentation using 3rd party tool\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
