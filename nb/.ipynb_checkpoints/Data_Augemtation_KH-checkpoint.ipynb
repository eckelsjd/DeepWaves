{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "LYJNjbibynk5",
    "outputId": "ff2617f4-4b04-4ad1-93b4-82d6115fdebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
      "\u001b[?25hCollecting torchvision==0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 44.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.5.1+cu101\n",
      "    Uninstalling torch-1.5.1+cu101:\n",
      "      Successfully uninstalled torch-1.5.1+cu101\n",
      "  Found existing installation: torchvision 0.6.1+cu101\n",
      "    Uninstalling torchvision-0.6.1+cu101:\n",
      "      Successfully uninstalled torchvision-0.6.1+cu101\n",
      "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"torch==1.4\" \"torchvision==0.5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DnkL5Ypyuo6"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_4XElgFyxoB"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "m0T9Qdb5yzVz",
    "outputId": "3c867705-07f6-4966-be37-f042fc00f757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kuYR1w_yzcA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "folder_path = '/content/gdrive/My Drive/Fruits'\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "y79DLUZG2Q3V",
    "outputId": "8a14d492-a0ff-4aec-9193-a50e0e1f3c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bananas\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherries\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oranges\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passionfruits\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watermelons\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create paths for the original, traning, and validation dataset.\n",
    "path = Path(folder_path) # Path to the whole folder\n",
    "folders = ['Original','Training','Validation','Augmented']\n",
    "paths = [] # store the paths to each folder\n",
    "for f in folders:\n",
    "  paths.append(Path(folder_path + '/' + f))\n",
    "\n",
    "#oripath = Path(folder_path+'/Original')\n",
    "#trainpath = Path(folder_path +'/Training')\n",
    "#validpath = Path(folder_path+'/Validation')\n",
    "#testpath = Path(folder_path+'/MiniProject_Watermelon')\n",
    "#augpath = Path(folder_path+'Augmented')\n",
    "\n",
    "classes = ['Apples','Bananas','Cherries','Oranges','Passionfruits','Watermelons']\n",
    "for c in classes:\n",
    "  print(c)\n",
    "  for i in range(0, len(paths)):\n",
    "    verify_images(paths[i]/c, delete=True, max_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "PsogkDkoLYM-",
    "outputId": "89fb5983-51eb-454e-ca93-0eeb31b74845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "120\n",
      "123\n",
      "132\n",
      "97\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "# Get a list of images from the original dataset.\n",
    "OriImages = []\n",
    "for c in classes:\n",
    "  il_data = ImageList.from_folder(paths[0]/c, extensions=['.jpg'])\n",
    "  OriImages.append(il_data)\n",
    "for j in range(0,len(OriImages)):\n",
    "  print(len(OriImages[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "ZX8s2SNJaFNv",
    "outputId": "386ce490-ef3d-41b9-d9f6-f4d1336b1061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ImageList (218 items)\n",
      "Image (3, 183, 275),Image (3, 217, 232),Image (3, 214, 236),Image (3, 168, 299),Image (3, 225, 225)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Apples, ImageList (96 items)\n",
      "Image (3, 183, 275),Image (3, 198, 255),Image (3, 183, 275),Image (3, 225, 225),Image (3, 179, 281)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Bananas, ImageList (99 items)\n",
      "Image (3, 275, 183),Image (3, 243, 207),Image (3, 225, 225),Image (3, 194, 259),Image (3, 195, 259)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Cherries, ImageList (106 items)\n",
      "Image (3, 189, 267),Image (3, 220, 229),Image (3, 151, 333),Image (3, 225, 225),Image (3, 275, 184)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Oranges, ImageList (78 items)\n",
      "Image (3, 193, 261),Image (3, 194, 259),Image (3, 168, 300),Image (3, 225, 225),Image (3, 167, 302)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Passionfruits, ImageList (108 items)\n",
      "Image (3, 194, 259),Image (3, 225, 225),Image (3, 244, 207),Image (3, 201, 251),Image (3, 184, 273)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Watermelons] [ImageList (54 items)\n",
      "Image (3, 275, 183),Image (3, 173, 292),Image (3, 225, 225),Image (3, 172, 293),Image (3, 177, 285)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Apples, ImageList (24 items)\n",
      "Image (3, 168, 300),Image (3, 194, 259),Image (3, 170, 297),Image (3, 225, 225),Image (3, 194, 259)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Bananas, ImageList (24 items)\n",
      "Image (3, 112, 450),Image (3, 196, 257),Image (3, 168, 299),Image (3, 190, 265),Image (3, 182, 277)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Cherries, ImageList (26 items)\n",
      "Image (3, 183, 275),Image (3, 238, 212),Image (3, 225, 225),Image (3, 224, 224),Image (3, 194, 259)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Oranges, ImageList (19 items)\n",
      "Image (3, 276, 183),Image (3, 225, 225),Image (3, 187, 269),Image (3, 225, 225),Image (3, 169, 299)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Passionfruits, ImageList (26 items)\n",
      "Image (3, 164, 307),Image (3, 184, 274),Image (3, 174, 290),Image (3, 183, 276),Image (3, 168, 299)\n",
      "Path: /content/gdrive/My Drive/Fruits/Original/Watermelons]\n"
     ]
    }
   ],
   "source": [
    "# Split the original dataset into training dataset and validation dataset.\n",
    "TrainingDataset = []\n",
    "ValidationDataset = []\n",
    "for k in range(0, len(OriImages)):\n",
    "  Datasets = OriImages[k].split_by_rand_pct()\n",
    "  TrainingDataset.append(Datasets.train)\n",
    "  ValidationDataset.append(Datasets.valid)\n",
    "print(TrainingDataset, ValidationDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4N0mvVxukf4"
   },
   "outputs": [],
   "source": [
    "# def get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10., max_zoom:float=1.1,\n",
    "#                    max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "#                    p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "#     \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "#     res = [rand_crop()]\n",
    "#     if do_flip:    res.append(dihedral_affine() if flip_vert else flip_lr(p=0.5))\n",
    "#     if max_warp:   res.append(symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine))\n",
    "#     if max_rotate: res.append(rotate(degrees=(-max_rotate,max_rotate), p=p_affine))\n",
    "#     if max_zoom>1: res.append(rand_zoom(scale=(1.,max_zoom), p=p_affine))\n",
    "#     if max_lighting:\n",
    "#         res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))\n",
    "#         res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))\n",
    "#     #       train                   , valid\n",
    "#     return (res + listify(xtra_tfms), [crop_pad()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IX6eFnVkttz8"
   },
   "outputs": [],
   "source": [
    "# def transforms()->Collection[Transform]:\n",
    "#     p_affine = 0.75 # default = 0.75\n",
    "#     min_zoom = 0.5\n",
    "#     max_zoom = 2.\n",
    "#     max_rotate = 180.\n",
    "#     max_lighting = 0.5\n",
    "#     p_lighting = 0.75 # default = 0.75 \n",
    "#     jitter_mag = 0.03\n",
    "#     per_wrap_mag = 0.5\n",
    "#     skew_mag = 0.5\n",
    "#     squ_scale = 0.01\n",
    "#     sym_mag = 0.4\n",
    "\n",
    "#     tfms = [zoom_crop(scale=(min_zoom,max_zoom), do_rand=True, p=p_affine),         # random crop and zoom\n",
    "#             rand_resize_crop(224, max_scale=max_zoom),                              # random resize and crop\n",
    "#             rotate(degrees=(-max_rotate, max_rotate), p=p_affine),                  # rotation\n",
    "#             brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting),     # brightness\n",
    "#             contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting),                # contrast\n",
    "#             dihedral_affine(p=p_affine),                                            # if flip vert, use dihedral_affine \n",
    "#             flip_affine(p=p_affine),                                                # only horizontal flip\n",
    "#             jitter(magnitude=(-jitter_mag,jitter_mag)),                             # jitter\n",
    "#             perspective_warp(magnitude=(-per_wrap_mag,per_wrap_mag)),               # perspective_warp\n",
    "#             skew(direction=(0,7),magnitude=(-skew_mag,skew_mag),invert=True),       # skew\n",
    "#             squish(scale=(-squ_scale,squ_scale)),                                   # squish\n",
    "#             symmetric_warp(magnitude=(-sym_mag,sym_mag),p=p_affine,invert=True),    # wrap\n",
    "#             cutout()                                                                # cutout\n",
    "#             ]\n",
    "#         #       train                   , valid\n",
    "#     return (tfms[0], [crop_pad()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXD3Edx-X4GM"
   },
   "outputs": [],
   "source": [
    "# Write our own transformations function.\n",
    "p_affine = 1. # default = 0.75\n",
    "min_zoom = 0.5\n",
    "max_zoom = 2.\n",
    "max_rotate = 180.\n",
    "max_lighting = 0.5\n",
    "p_lighting = 1. # default = 0.75 \n",
    "jitter_mag = 0.03\n",
    "per_wrap_mag = 0.5\n",
    "skew_mag = 0.5\n",
    "squ_scale = 0.01\n",
    "sym_mag = 0.4\n",
    "\n",
    "tfms = [zoom_crop(scale=(min_zoom,max_zoom), do_rand=True, p=p_affine),         # random crop and zoom (v)\n",
    "        #rand_resize_crop(224, max_scale=max_zoom),                              # random resize and crop (v)\n",
    "        rotate(degrees=(-max_rotate, max_rotate), p=p_affine),                  # rotation (v)\n",
    "        #brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting),     # brightness\n",
    "        #contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting),                # contrast (?)\n",
    "        dihedral_affine(p=p_affine),                                            # if flip vert, use dihedral_affine (v)\n",
    "        flip_affine(p=p_affine),                                                # only horizontal flip (v)\n",
    "        #jitter(magnitude=(-jitter_mag,jitter_mag)),                             # jitter (?)\n",
    "        #perspective_warp(magnitude=(-per_wrap_mag,per_wrap_mag)),               # perspective_warp\n",
    "        #skew(direction=(0,7),magnitude=(-skew_mag,skew_mag),invert=True),       # skew\n",
    "        #squish(scale=(-squ_scale,squ_scale)),                                   # squish\n",
    "        #symmetric_warp(magnitude=(-sym_mag,sym_mag),p=p_affine,invert=True),    # wrap\n",
    "        #cutout()                                                                # cutout\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "LG70ITcu5gQy",
    "outputId": "74dab751-a061-404e-9b9b-5d6761924464"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-33dafe9c6260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://i.guim.co.uk/img/media/4ddba561156645952502f7241bd1a64abd0e48a3/0_1251_3712_2225/master/3712.jpg?width=1920&quality=85&auto=format&fit=max&s=1280341b186f8352416517fc997cd7da\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplotnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'skimage' has no attribute 'io'"
     ]
    }
   ],
   "source": [
    "# Noise Function Not Complete Yet (Don't Run!)\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "img_path=\"https://i.guim.co.uk/img/media/4ddba561156645952502f7241bd1a64abd0e48a3/0_1251_3712_2225/master/3712.jpg?width=1920&quality=85&auto=format&fit=max&s=1280341b186f8352416517fc997cd7da\"\n",
    "img = skimage.io.imread(img_path)/255.0\n",
    "\n",
    "def plotnoise(img, mode, r, c, i):\n",
    "    plt.subplot(r,c,i)\n",
    "    if mode is not None:\n",
    "        gimg = skimage.util.random_noise(img, mode=mode)\n",
    "        plt.imshow(gimg)\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(mode)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(18,24))\n",
    "r=4\n",
    "c=2\n",
    "plotnoise(img, \"gaussian\", r,c,1)\n",
    "plotnoise(img, \"localvar\", r,c,2)\n",
    "plotnoise(img, \"poisson\", r,c,3)\n",
    "plotnoise(img, \"salt\", r,c,4)\n",
    "plotnoise(img, \"pepper\", r,c,5)\n",
    "plotnoise(img, \"s&p\", r,c,6)\n",
    "plotnoise(img, \"speckle\", r,c,7)\n",
    "plotnoise(img, None, r,c,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "vkM_IMlw9fCH",
    "outputId": "792c7e17-6062-4105-de7c-a7255d521bf8"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9213d8fa35ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTrainImages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Add salt-and-pepper noise to the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not PosixPath"
     ]
    }
   ],
   "source": [
    "# Noise Function Not Complete Yet (Don't Run!)\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    " \n",
    "# Load the image\n",
    "img = cv2.imread(\"D:/downloads/opencv_logo.PNG\")\n",
    " \n",
    "# Add salt-and-pepper noise to the image.\n",
    "noise_img = random_noise(img, mode='s&p',amount=0.3)\n",
    " \n",
    "# The above function returns a floating-point image\n",
    "# on the range [0, 1], thus we changed it to 'uint8'\n",
    "# and from [0,255]\n",
    "noise_img = np.array(255*noise_img, dtype = 'uint8')\n",
    " \n",
    "# Display the noise image\n",
    "cv2.imshow('blur',noise_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6nHNcFRRb6G"
   },
   "outputs": [],
   "source": [
    "# Perform data augmentation on the original images and save the augmented images in the augmented dataset folder.\n",
    "for l in range(0,1):\n",
    "  for m in range(0,len(OriImages)):\n",
    "    for n in range(0,len(OriImages[m])):\n",
    "      for o in range(0, len(tfms)):\n",
    "        imagetfms = (OriImages[m][n]).apply_tfms(tfms[o], size=224)\n",
    "        imagetfms.save(paths[3]/classes[m]/('Aug'+str(o)+str(n)+'.jpg')) # May change .jpg to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LHJHviUAKqU1",
    "outputId": "8f6181fa-8426-472f-fbc3-6712d690dbb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastai.vision.image.Image'>\n"
     ]
    }
   ],
   "source": [
    "print(type(imagetfms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "KtqhaXodJ4YN",
    "outputId": "a458e8a6-b54b-492d-f268-729c2ae72e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088\n",
      "480\n",
      "492\n",
      "528\n",
      "388\n",
      "536\n"
     ]
    }
   ],
   "source": [
    "# Verify the augmented images are saved in the augmented set folder.\n",
    "AugImages = []\n",
    "for c in classes:\n",
    "  il_data = ImageList.from_folder(paths[3]/c)\n",
    "  AugImages.append(il_data)\n",
    "for p in range(0,len(AugImages)):\n",
    "  print(len(AugImages[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "9fsPWwpJ_Dwa",
    "outputId": "908f27dd-281e-43b9-ef1a-b929a5d6400b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "96\n",
      "99\n",
      "106\n",
      "78\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "for a in range(0, len(TrainingDataset)):\n",
    "  print(len(TrainingDataset[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "4qDtHwiYh_hg",
    "outputId": "df7dea5f-5842-4c29-b054-9f0f4fbda0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306\n",
      "576\n",
      "591\n",
      "634\n",
      "466\n",
      "644\n"
     ]
    }
   ],
   "source": [
    "# Add and verify the augmented data are added to the training dataset.\n",
    "for q in range(0,len(AugImages)):\n",
    "  TrainingDataset[q].add(AugImages[q])\n",
    "  print(len(TrainingDataset[q]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Lb-l8T8jGAW"
   },
   "outputs": [],
   "source": [
    "# Save the complete training dataset with data augmentation in the traninging dataset folder.\n",
    "for q in range(0,len(TrainingDataset)):\n",
    "  for r in range(0,len(TrainingDataset[q])):\n",
    "    image = TrainingDataset[q][r]\n",
    "    image.save(paths[1]/classes[q]/(str(r)+'.jpg')) # May change .jpg to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ik_LcrFUxQ8b",
    "outputId": "f54fa5e4-3170-4bb6-a2e5-8e333e1e1c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306\n",
      "576\n",
      "591\n",
      "634\n",
      "466\n",
      "644\n"
     ]
    }
   ],
   "source": [
    "# Verify the training dataset is saved in the training dataset folder.\n",
    "TImages = []\n",
    "for c in classes:\n",
    "  il_data = ImageList.from_folder(paths[1]/c)\n",
    "  TImages.append(il_data)\n",
    "for t in range(0,len(TImages)):\n",
    "  print(len(TImages[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34yhV4gCqPIA"
   },
   "outputs": [],
   "source": [
    "# Save the validation dataset in the validation dataset folder.\n",
    "for u in range(0,len(ValidationDataset)):\n",
    "  for v in range(0,len(ValidationDataset[u])):\n",
    "    image = ValidationDataset[u][v]\n",
    "    image.save(paths[2]/classes[u]/(str(v)+'.jpg')) # May change .jpg to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2c_yJ7zKdqyS",
    "outputId": "eec66953-fab7-436a-bae4-13f1b7d949e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "24\n",
      "24\n",
      "26\n",
      "19\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# Verify the validation dataset is saved in the validation dataset folder.\n",
    "VImages = []\n",
    "for c in classes:\n",
    "  il_data = ImageList.from_folder(paths[2]/c)\n",
    "  VImages.append(il_data)\n",
    "for w in range(0,len(VImages)):\n",
    "  print(len(VImages[w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "mpli45WDKiio",
    "outputId": "965a8a20-5e3a-46c1-9e62-797c87e7443e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apples', 'Bananas', 'Cherries', 'Oranges', 'Passionfruits', 'Watermelons'] ImageDataBunch;\n",
      "\n",
      "Train: LabelList (4217 items)\n",
      "x: ImageList\n",
      "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
      "y: CategoryList\n",
      "Apples,Apples,Apples,Apples,Apples\n",
      "Path: /content/gdrive/My Drive/Fruits;\n",
      "\n",
      "Valid: LabelList (173 items)\n",
      "x: ImageList\n",
      "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
      "y: CategoryList\n",
      "Apples,Apples,Apples,Apples,Apples\n",
      "Path: /content/gdrive/My Drive/Fruits;\n",
      "\n",
      "Test: LabelList (18 items)\n",
      "x: ImageList\n",
      "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
      "y: EmptyLabelList\n",
      ",,,,\n",
      "Path: /content/gdrive/My Drive/Fruits\n"
     ]
    }
   ],
   "source": [
    "# Create databunch.\n",
    "data = ImageDataBunch.from_folder(path, train='Training', valid='Validation', test='MiniProject_Watermelon',\n",
    "        ds_tfms=None, size=224, num_workers=0).normalize(imagenet_stats)\n",
    "print(data.classes, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kujU3_R6Ki4Z"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
    "\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_p36Qan8KjJm"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-1')\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21Dt7WixeYRa"
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpLcm7UaeYyr"
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMBqkQBrfHPH"
   },
   "outputs": [],
   "source": [
    "# Original data / Fine tuning / Resnet 34\n",
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTWDizVIfGap"
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABzFmSSBfSI6"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, max_lr=slice(5e-6,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSScKckYfR9A"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-2')\n",
    "learn.load('stage-2')\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkIRu9IQfRxQ"
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNQcis5LfRkQ"
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCP2DDc4fRa-"
   },
   "outputs": [],
   "source": [
    "#preds,y = learn.get_preds(ds_type=DatasetType.Test)\n",
    "print(learn.get_preds(ds_type=DatasetType.Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzk4qzvhioha"
   },
   "outputs": [],
   "source": [
    "img1 = open_image(testpath/'20200611_195938.jpg')\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1BhGjzWio3f"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img1)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WFDjWyoipcJ"
   },
   "outputs": [],
   "source": [
    "img2 = open_image(testpath/'20200612_162243.jpg')\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmS08lxpipMc"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img2)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcyYVNyyjOfL"
   },
   "outputs": [],
   "source": [
    "img3 = open_image(testpath/'20200612_162252.jpg')\n",
    "img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1_lk-AJjO_-"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img3)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8VJx36-jQhw"
   },
   "outputs": [],
   "source": [
    "img4 = open_image(testpath/'20200623_153800.jpg')\n",
    "img4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PCmajaKjQVR"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img4)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kntjAlzijQIq"
   },
   "outputs": [],
   "source": [
    "img5 = open_image(testpath/'20200623_153842.jpg')\n",
    "img5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXJ5cCasjP8v"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img5)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmyE2HmTjP4h"
   },
   "outputs": [],
   "source": [
    "img6 = open_image(testpath/'20200623_154026.jpg')\n",
    "img6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSuMdgjFjPjZ"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img6)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnQg-l_vjPgq"
   },
   "outputs": [],
   "source": [
    "img7 = open_image(testpath/'20200623_154047.jpg')\n",
    "img7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o86U_iKpjPQ5"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img7)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3y3WL0QtkbhN"
   },
   "outputs": [],
   "source": [
    "img8 = open_image(testpath/'20200623_154142.jpg')\n",
    "img8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IN1jG1Z9kdTx"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img8)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkmn5YbHkdBr"
   },
   "outputs": [],
   "source": [
    "img9 = open_image(testpath/'20200623_154217.jpg')\n",
    "img9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxDMKLT8kc-o"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img9)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BO-DvrOkctm"
   },
   "outputs": [],
   "source": [
    "img10 = open_image(testpath/'20200623_154310.jpg')\n",
    "img10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-tR1s-6kcqN"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img10)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0jls6QQkcF1"
   },
   "outputs": [],
   "source": [
    "img11 = open_image(testpath/'20200623_154327.jpg')\n",
    "img11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_B0ZQvnkb3Y"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img11)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axGVuNjNlhqU"
   },
   "outputs": [],
   "source": [
    "img12 = open_image(testpath/'20200623_154844.jpg')\n",
    "img12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1un-DGC6liEj"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img12)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRt58AacliXH"
   },
   "outputs": [],
   "source": [
    "img13 = open_image(testpath/'Fruit.jpg')\n",
    "img13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzXh6-zTl36p"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img13)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzRnJOeil47N"
   },
   "outputs": [],
   "source": [
    "img14 = open_image(testpath/'20200623_123827.jpg')\n",
    "img14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDu5uFbSl4r6"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img14)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLiFu2wpl4Wi"
   },
   "outputs": [],
   "source": [
    "img15 = open_image(testpath/'20200623_100544.jpg')\n",
    "img15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjN8J7wZmU3g"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img15)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znxLNbSvmWKT"
   },
   "outputs": [],
   "source": [
    "img16 = open_image(testpath/'IMG-2342.JPG')\n",
    "img16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MyTzZ0ImmVT"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img16)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LYK8LVLmmy4"
   },
   "outputs": [],
   "source": [
    "img17 = open_image(testpath/'IMG_20200624_094151.jpg')\n",
    "img17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqW6E_zMmnN5"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img17)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pvdQvgcm0ul"
   },
   "outputs": [],
   "source": [
    "img18 = open_image(testpath/'IMG_20200624_094350.jpg')\n",
    "img18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hAZZnVQm1MW"
   },
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img18)\n",
    "pred_class.obj, pred_class, pred_idx,outputs, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRaSUHQtm-n-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVLaFrKb2Q-_"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation OFF\n",
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_folder(oripath, train='.', valid_pct=0.2,\n",
    "        ds_tfms=None, size=224, num_workers=0).normalize(imagenet_stats)\n",
    "\n",
    "data.classes\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RZpxFKZ4JS_"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
    "\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtNXv8RN4Jbn"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation ON with get_transforms function\n",
    "np.random.seed(42)\n",
    "datatfm = ImageDataBunch.from_folder(path, train='.', valid_pct=0.2,\n",
    "        ds_tfms=get_transforms(), size=224, num_workers=0).normalize(imagenet_stats)\n",
    "\n",
    "datatfm.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjuLYsQa4JkF"
   },
   "outputs": [],
   "source": [
    "learntfm = cnn_learner(datatfm, models.resnet34, metrics=error_rate)\n",
    "\n",
    "learntfm.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDcAGJFe4Jts"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation ON with our own transforms function\n",
    "np.random.seed(42)\n",
    "datatfmown = ImageDataBunch.from_folder(path, train=path, valid=, valid_pct=0.2,\n",
    "        ds_tfms=transforms(), size=224, num_workers=0).normalize(imagenet_stats)\n",
    "\n",
    "datatfmown.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahvt7H17rO83"
   },
   "outputs": [],
   "source": [
    "learntfmown = cnn_learner(datatfmown, models.resnet34, metrics=error_rate)\n",
    "\n",
    "learntfmown.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9414SMFArPfT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChLj7KFnrPOG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19krcZ_B9XKN"
   },
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "Imagepath = Path('/content/gdrive/My Drive/MiniProject_Watermelon')\n",
    "dest = Imagepath\n",
    "dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zA74NSU4Jsg"
   },
   "outputs": [],
   "source": [
    "# Helper functions from fastai docs\n",
    "def get_ex(): return open_image(Imagepath/'20200623_154026.jpg')\n",
    "\n",
    "def plots_f(rows, cols, width, height, **kwargs):\n",
    "    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "        rows,cols,figsize=(width,height))[1].flatten())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MW2_kvXj8myS"
   },
   "outputs": [],
   "source": [
    "# Default Data Augmentation\n",
    "plots_f(1, 5, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_WEwzoH8m6L"
   },
   "outputs": [],
   "source": [
    "# Rotation\n",
    "tfms = get_transforms(max_rotate=360)\n",
    "plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXfuQukj8nIo"
   },
   "outputs": [],
   "source": [
    "# Change the size of the images\n",
    "plots_f(2, 4, 12, 6, size=(300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mwIxZ4j8nP_"
   },
   "outputs": [],
   "source": [
    "# Padding zeros (black) for missing pixels\n",
    "plots_f(2, 4, 12, 6, size=224, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i97_j3ao8mpC"
   },
   "outputs": [],
   "source": [
    "# Set the missing pixels to the value of the pixel at the nearest border\n",
    "plots_f(2, 4, 12, 6, size=224, padding_mode='border')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w15852i_TPl"
   },
   "outputs": [],
   "source": [
    "# Set the missing pixels to the value of the pixel symmetric to the nearest border\n",
    "plots_f(2, 4, 12, 6, size=224, padding_mode='reflection') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkFrowhb_ZSx"
   },
   "outputs": [],
   "source": [
    "# Randomly zoom and/or crop\n",
    "tfms = zoom_crop(scale=(0.75,2), do_rand=True)\n",
    "plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SD1s08QAEjF"
   },
   "outputs": [],
   "source": [
    "# Randomly resize and crop the image to a ratio in ratios after a zoom of max_scale\n",
    "tfms = [rand_resize_crop(224)]\n",
    "plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syPkY893AFKN"
   },
   "outputs": [],
   "source": [
    "# Ramdomize rotation angles\n",
    "tfm = [rotate(degrees=(-30,30), p=0.75)]\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for ax in axs:\n",
    "    img = get_ex().apply_tfms(tfm)\n",
    "    title = f\"Done, deg={tfm[0].resolved['degrees']:.1f}\" if tfm[0].do_run else f'Not done'\n",
    "    img.show(ax=ax, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-k_ep7NwAFTO"
   },
   "outputs": [],
   "source": [
    "# Brightness\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for change, ax in zip(np.linspace(0.1,0.9,5), axs):\n",
    "    brightness(get_ex(), change).show(ax=ax, title=f'change={change:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGbd_7Q6AFdq"
   },
   "outputs": [],
   "source": [
    "# Contrast\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for scale, ax in zip(np.exp(np.linspace(log(0.5),log(2),5)), axs):\n",
    "    contrast(get_ex(), scale).show(ax=ax, title=f'scale={scale:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMP_5ibFAFpZ"
   },
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for center, ax in zip([[0.,0.], [0.,1.],[0.5,0.5],[1.,0.], [1.,1.]], axs):\n",
    "    crop(get_ex(), 300, *center).show(ax=ax, title=f'center=({center[0]}, {center[1]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upak-AdnBtuG"
   },
   "outputs": [],
   "source": [
    "# Combines a flip (horizontal or vertical) and a rotation of a multiple of 90 degrees\n",
    "fig, axs = plt.subplots(2,4,figsize=(12,8))\n",
    "for k, ax in enumerate(axs.flatten()):\n",
    "    dihedral(get_ex(), k).show(ax=ax, title=f'k={k}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yrp99Ka5B5Nj"
   },
   "outputs": [],
   "source": [
    "# changes the pixels of the image by randomly replacing them with pixels from the neighborhood\n",
    "# (how far the neighborhood extends is controlled by the value of magnitude)\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for magnitude, ax in zip(np.linspace(-0.05,0.05,5), axs):\n",
    "    tfm = jitter(magnitude=magnitude)\n",
    "    get_ex().jitter(magnitude).show(ax=ax, title=f'magnitude={magnitude:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG0TJO3xCWuJ"
   },
   "outputs": [],
   "source": [
    "# Changes the perspective of the image as if our object was moved around\n",
    "fig, axs = plt.subplots(2,4,figsize=(12,8))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    magnitudes = torch.tensor(np.zeros(8))\n",
    "    magnitudes[i] = 0.5\n",
    "    perspective_warp(get_ex(), magnitudes).show(ax=ax, title=f'coord {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZL7r1shCljg"
   },
   "outputs": [],
   "source": [
    "# Randomize one of the color channels of the input image\n",
    "fig, axs = plt.subplots(3,3,figsize=(12,12))\n",
    "channels = ['Red', 'Green', 'Blue']\n",
    "\n",
    "for i in np.arange(0, 3):\n",
    "    for thresh, ax in zip(np.linspace(0.2, 0.99, 3), axs[:, i]):\n",
    "        get_ex().rgb_randomize(channel = i, thresh = thresh).show(\n",
    "            ax=ax, title = f'{channels[i]}, thresh={thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lupsJNDzDMsP"
   },
   "outputs": [],
   "source": [
    "# Skew\n",
    "fig, axs = plt.subplots(2,4,figsize=(12,8))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    get_ex().skew(i, 0.2).show(ax=ax, title=f'direction={i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPOirYKfDUEB"
   },
   "outputs": [],
   "source": [
    "# Squish\n",
    "fig, axs = plt.subplots(1,5,figsize=(12,4))\n",
    "for scale, ax in zip(np.linspace(0.66,1.33,5), axs):\n",
    "    get_ex().squish(scale=scale).show(ax=ax, title=f'scale={scale:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdJtbxf5Dhw9"
   },
   "outputs": [],
   "source": [
    "# Tilt\n",
    "fig, axs = plt.subplots(2,4,figsize=(12,8))\n",
    "for i in range(4):\n",
    "    get_ex().tilt(i, 0.4, invert=True).show(ax=axs[0,i], title=f'direction={i}, fwd')\n",
    "    get_ex().tilt(i, -0.4, invert=True).show(ax=axs[1,i], title=f'direction={i}, bwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKt1tXZjDmM8"
   },
   "outputs": [],
   "source": [
    "# Randomized version of zoom\n",
    "tfm = rand_zoom(scale=(1.,1.5))\n",
    "_, axs = plt.subplots(2,4,figsize=(12,6))\n",
    "for ax in axs.flatten():\n",
    "    img = get_ex().apply_tfms(tfm)\n",
    "    img.show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GhpyloRD5fI"
   },
   "outputs": [],
   "source": [
    "# Randomized version of crop\n",
    "tfm = rand_crop()\n",
    "_, axs = plt.subplots(2,4,figsize=(12,6))\n",
    "for ax in axs.flatten():\n",
    "    img = get_ex().apply_tfms(tfm, size=224)\n",
    "    img.show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FK0JM2WyEGdo"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dataAug = ImageDataBunch.from_folder(path, train='.', valid_pct=0.2,\n",
    "        ds_tfms=get_transforms(flip_vert=True, max_rotate=360.0, max_zoom=1.5), size=224, num_workers=0).normalize(imagenet_stats)\n",
    "\n",
    "dataAug.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQqGqBNfGuwG"
   },
   "outputs": [],
   "source": [
    "dataAug.show_batch(rows=3, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJ6-mht4G3yT"
   },
   "outputs": [],
   "source": [
    "learnAug = cnn_learner(dataAug, models.resnet34, metrics=error_rate)\n",
    "learnAug.fit_one_cycle(4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Augemtation_KH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
